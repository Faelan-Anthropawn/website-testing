<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Audio Visualizer Export</title>
<style>
  body {
    background: #0f0f0f;
    color: #e5e5e5;
    font-family: system-ui, sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 16px;
    padding: 20px;
  }
  canvas {
    border-radius: 12px;
    background: black;
  }
  button {
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
  }
</style>
</head>
<body>

<h2>Browser Audio Visualizer â†’ Video</h2>
<canvas id="canvas" width="1280" height="720"></canvas>
<button id="render">Render Video</button>

<script>
const WIDTH = 1280;
const HEIGHT = 720;
const FPS = 60;

const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

async function loadImage(src) {
  return new Promise(res => {
    const img = new Image();
    img.onload = () => res(img);
    img.src = src;
  });
}

async function loadAudio(ctx, src) {
  const res = await fetch(src);
  const buf = await res.arrayBuffer();
  return ctx.decodeAudioData(buf);
}

document.getElementById("render").onclick = async () => {
  console.log("Render clicked");

  const img = await loadImage("image.png");

  const audioCtx = new AudioContext();
  await audioCtx.resume();

  const audioBuffer = await loadAudio(audioCtx, "audio.mp3");

  const source = audioCtx.createBufferSource();
  source.buffer = audioBuffer;

  const analyser = audioCtx.createAnalyser();
  analyser.fftSize = 256;
  analyser.smoothingTimeConstant = 0.8;

  const gain = audioCtx.createGain();
  gain.gain.value = 1;

  const mediaDest = audioCtx.createMediaStreamDestination();

  source.connect(analyser);
  analyser.connect(gain);
  gain.connect(audioCtx.destination);
  gain.connect(mediaDest);

  const canvasStream = canvas.captureStream(FPS);

  const stream = new MediaStream([
    ...canvasStream.getVideoTracks(),
    ...mediaDest.stream.getAudioTracks()
  ]);

  const recorder = new MediaRecorder(stream, {
    mimeType: MediaRecorder.isTypeSupported("video/webm;codecs=vp9,opus")
      ? "video/webm;codecs=vp9,opus"
      : "video/webm;codecs=vp8,opus",
    videoBitsPerSecond: 6_000_000
  });

  const chunks = [];
  recorder.ondataavailable = e => chunks.push(e.data);

  const BAR_COUNT = 64;
  const dataArray = new Uint8Array(analyser.frequencyBinCount);

  function draw() {
    requestAnimationFrame(draw);

    analyser.getByteFrequencyData(dataArray);

    ctx.clearRect(0, 0, WIDTH, HEIGHT);
    ctx.drawImage(img, 0, 0, WIDTH, HEIGHT);

    const barWidth = WIDTH / BAR_COUNT;
    const step = Math.max(1, Math.floor(dataArray.length / BAR_COUNT));

    for (let i = 0; i < BAR_COUNT; i++) {
      const v = dataArray[i * step] / 255;
      const h = v * (HEIGHT * 0.45);

      const r = Math.floor(255 * v);
      const g = Math.floor(200 * (i / BAR_COUNT));
      const b = 100;

      ctx.fillStyle = `rgb(${r}, ${g}, ${b})`;
      ctx.fillRect(
        i * barWidth,
        HEIGHT - h,
        barWidth * 0.9,
        h
      );
    }
  }

  // start everything in the correct order
  draw();
  recorder.start();
  source.start();

  setTimeout(() => recorder.stop(), audioBuffer.duration * 1000);

  recorder.onstop = () => {
    const blob = new Blob(chunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = "visualizer.webm";
    a.click();
    URL.revokeObjectURL(url);
  };
};
</script>

</body>
</html>
