<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Audio Visualizer Export</title>
<style>
  body {
    background: #0f0f0f;
    color: #e5e5e5;
    font-family: system-ui, sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 16px;
    padding: 20px;
  }
  canvas {
    border-radius: 12px;
    background: black;
  }
  button {
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
  }
</style>
</head>
<body>

<h2>Browser Audio Visualizer → Video</h2>
<canvas id="canvas" width="1280" height="720"></canvas>
<button id="render">Render Video</button>

<script>
/* -------- CONFIG -------- */

const WIDTH = 1280;
const HEIGHT = 720;
const FPS = 60;
const BAR_COLOR = "#22c55e";

const FFT_SIZE = 2048;
const MIN_BIN = 4;          // ignore sub-bass/DC
const MAX_HEIGHT = HEIGHT * 0.35;
const SMOOTHING = 0.85;

/* ------------------------ */

const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

async function loadImage(src) {
  return new Promise(res => {
    const img = new Image();
    img.onload = () => res(img);
    img.src = src;
  });
}

async function loadAudio(ctx, src) {
  const res = await fetch(src);
  const buf = await res.arrayBuffer();
  return ctx.decodeAudioData(buf);
}

document.getElementById("render").onclick = async () => {
  console.log("Render clicked");

  const img = await loadImage("image.png");

  const audioCtx = new AudioContext();
  await audioCtx.resume(); // ✅ REQUIRED

  const audioBuffer = await loadAudio(audioCtx, "audio.mp3");

  const source = audioCtx.createBufferSource();
  source.buffer = audioBuffer;

  const analyser = audioCtx.createAnalyser();
  analyser.fftSize = FFT_SIZE;
  analyser.smoothingTimeConstant = SMOOTHING;

  const gain = audioCtx.createGain();
  gain.gain.value = 1;

  const mediaDest = audioCtx.createMediaStreamDestination();

  source.connect(analyser);
  analyser.connect(gain);

  // route audio to BOTH speakers and recorder
  gain.connect(audioCtx.destination);
  gain.connect(mediaDest);

  const canvasStream = canvas.captureStream(FPS);
  const audioStream = mediaDest.stream;


  const stream = new MediaStream([
    ...canvasStream.getVideoTracks(),
    ...audioStream.getAudioTracks()
  ]);

  const recorder = new MediaRecorder(stream, {
    mimeType: "video/webm;codecs=vp9,opus",
    videoBitsPerSecond: 6_000_000
  });

  const chunks = [];
  recorder.ondataavailable = e => chunks.push(e.data);

  /* ---- START AUDIO FIRST ---- */
  source.start();

  /* ---- START RECORDING NEXT FRAME ---- */
  requestAnimationFrame(() => recorder.start());

  const freqData = new Uint8Array(analyser.frequencyBinCount);

  function draw() {
    ctx.drawImage(img, 0, 0, WIDTH, HEIGHT);
    analyser.getByteFrequencyData(freqData);

    const usableBins = freqData.length - MIN_BIN;
    const barWidth = WIDTH / usableBins;

    ctx.fillStyle = BAR_COLOR;

    for (let i = MIN_BIN; i < freqData.length; i++) {
      const v = freqData[i] / 255;
      const scaled = Math.sqrt(v);
      const h = scaled * MAX_HEIGHT;

      ctx.fillRect(
        (i - MIN_BIN) * barWidth,
        HEIGHT - h,
        barWidth * 0.9,
        h
      );
    }

    requestAnimationFrame(draw);
  }

  draw();

  setTimeout(() => recorder.stop(), audioBuffer.duration * 1000);

  recorder.onstop = () => {
    const blob = new Blob(chunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.href = url;
    a.download = "visualizer.webm";
    a.click();

    URL.revokeObjectURL(url);
  };
};
</script>

</body>
</html>



