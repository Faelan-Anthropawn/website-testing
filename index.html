<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Audio Visualizer Export</title>
<style>
  body {
    background: #0f0f0f;
    color: #e5e5e5;
    font-family: system-ui, sans-serif;
    display: flex;
    flex-direction: column;
    align-items: center;
    gap: 16px;
    padding: 20px;
  }
  canvas {
    border-radius: 12px;
    background: black;
  }
  button {
    padding: 10px 16px;
    font-size: 16px;
    cursor: pointer;
  }
</style>
</head>
<body>

<h2>Browser Audio Visualizer â†’ Video</h2>
<canvas id="canvas" width="1280" height="720"></canvas>
<button id="render">Render Video</button>

<script>
document.getElementById("render").onclick = async () => {
  console.log("Render clicked");

  const img = await loadImage("image.png");

  const audioCtx = new AudioContext();
  await audioCtx.resume();

  const audioBuffer = await loadAudio(audioCtx, "audio.mp3");

  const source = audioCtx.createBufferSource();
  source.buffer = audioBuffer;

  const analyser = audioCtx.createAnalyser();
  analyser.fftSize = 256;
  analyser.smoothingTimeConstant = 0.8;

  const gain = audioCtx.createGain();
  gain.gain.value = 1;

  const mediaDest = audioCtx.createMediaStreamDestination();

  source.connect(analyser);
  analyser.connect(gain);
  gain.connect(audioCtx.destination);
  gain.connect(mediaDest);

  const canvasStream = canvas.captureStream(FPS);
  const audioStream = mediaDest.stream;

  const stream = new MediaStream([
    ...canvasStream.getVideoTracks(),
    ...audioStream.getAudioTracks()
  ]);

  const recorder = new MediaRecorder(stream, {
    mimeType: MediaRecorder.isTypeSupported("video/webm;codecs=vp9,opus")
      ? "video/webm;codecs=vp9,opus"
      : "video/webm;codecs=vp8,opus",
    videoBitsPerSecond: 6_000_000
  });

  const chunks = [];
  recorder.ondataavailable = e => chunks.push(e.data);

  // start audio + recorder after one render frame
  requestAnimationFrame(() => {
    recorder.start();
    source.start();
  });

  const bufferLength = analyser.frequencyBinCount;
  const dataArray = new Uint8Array(bufferLength);

  const BAR_COUNT = bufferLength;
  const BAR_WIDTH = (WIDTH / BAR_COUNT) * 2.5;

  function draw() {
    analyser.getByteFrequencyData(dataArray);

    // background
    ctx.fillStyle = "#000";
    ctx.fillRect(0, 0, WIDTH, HEIGHT);

    let x = 0;
    for (let i = 0; i < BAR_COUNT; i++) {
      const barHeight = dataArray[i];

      // colorful coloring logic (from the CodePen)
      const r = barHeight + (25 * (i / BAR_COUNT));
      const g = 250 * (i / BAR_COUNT);
      const b = 50;

      ctx.fillStyle = `rgb(${r}, ${g}, ${b})`;
      ctx.fillRect(
        x,
        HEIGHT - barHeight,
        BAR_WIDTH,
        barHeight
      );

      x += BAR_WIDTH + 1;
    }

    // draw static image under or above bars
    ctx.drawImage(img, 0, 0, WIDTH, HEIGHT);

    requestAnimationFrame(draw);
  }

  draw();

  recorder.onstop = () => {
    const blob = new Blob(chunks, { type: "video/webm" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = "visualizer.webm";
    a.click();
    URL.revokeObjectURL(url);
  };

  setTimeout(() => recorder.stop(), audioBuffer.duration * 1000);
};
</script>
</body>
</html>




